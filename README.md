# realtime-rendering

## 图形渲染管线

### 2.2 应用阶段

开发者对于应用阶段有完全的控制权，因为它在CPU上面运行。所以开发者可以完全确定怎么实现，并且通过修改来改进性能。这里的改变也能影响到后续几个阶段。比如应用阶段的算法或者设置可以减少需要渲染的三角形数量。

所有一切说明，有一些应用工作可以被放在GPU上执行，使用一种叫做compute shader的分离模式进行。这种模式把GPU当作一个高并发通用处理器。

在应用阶段的最后，需要被渲染的几何体会被送到几何处理阶段。这些就是rendering primitives渲染图元，也就是点、线、三角形。这就是应用阶段最重要的事情。

基于软件实现此阶段的结果就是它不能被分解成更小的子阶段substages（当然CPU自己可以被划分成流水线阶段，但和这里没有关联），不像几何处理、光栅化和像素处理阶段。但是，为了加强性能，这一阶段通常会在多核中并行被执行。在CPU设计中这被称为superscalar construction超标量构建，因为它能在一个阶段同时进行多次处理。18.5节展示了使用多处理核心的多种方法。

一个通常被用在此阶段的处理是碰撞检测collision detection。应用阶段也是读取其它输入源的地方，比如键盘、鼠标或者头戴式显示。加速算法，比如特殊的提出算法（19章）也是在这里实现的，需要用到其它管线不能处理的东西。

### 2.3 几何处理

GPU的几何处理阶段对遍历三角形per-triangle和遍历顶点per-vertex操作负责。这个阶段被进一步划分成几个功能阶段：vertex shading，projection，clipping，screen mapping

#### 2.3.1 顶点着色

在顶点着色阶段有两个主要的任务，计算顶点位置以及计算程序猿希望得到顶点什么样的输出，比如法线和纹理坐标。传统的做法是对每个顶点用光源遍历，然后把最终结果颜色存在顶点处。然后这些颜色就在三角形中进行插值。因为这个原因，可编程顶点处理单元也被称作顶点着色器。随着现代GPU的到来，顶点着色阶段变得更痛用了，并不完全是再去evaluate着色方程了，基于程序员的意愿。顶点着色器现在是一个更通用的单元，致力于设置与每个顶点相关联的数据。比如，丁带你着色器可以用第4.4和4.5的方法来制作物体动画。

我们开始描述顶点坐标是怎么被计算时，一系列坐标系就是必要的。

（略）

#### 2.3.2 可选的顶点处理

每个管线都有之前描述的顶点处理。当处理完成后，有一些可选的阶段可以在GPU上执行，顺序是：tessellation、geometry shading、stream output。它们的使用取决于硬件性能--不是所有GPU都有它们，以及程序员的意愿。它们互相独立，并且通常情况下它们不会被使用。更多情况会在第3章被说明。

第一个可选阶段是tessellation。想象你有一个弹力球物体。如果你用一系列三角形来表示则会遇到质量和效果问题。有了tessellation就能用恰当的三角形来细分曲面

我们谈论到了三角形，但是当前时刻的管线我们仅在处理顶点。这些顶点可以被用来描述点、直线、三角形或者其它物体。顶点可以被用来描述曲面，比如一个球。这种表面可以被一系列patches描述，每个patch都由一组顶点构成。tessellation它自己就由一系列阶段组成--hull shader、tessellator、domain shader--这把patch顶点组转成更大顶点组，然后被用来构成新的三角形组。场景相机可以被用来确定多少三角形被生成：越远越少。

接下来的阶段就是geometry shader。geometry shader早于tessellation shader出现，所以更普及。和tessellation shader相似，它获取多种图元，然后产生新的顶点。geometry shader有各种用途，最有名的一种是用于粒子生成。比如烟花，每个火焰球可以用点表示，一个顶点。geometry shader可以把点转换成矩形（两个三角形），朝向观察者并且覆盖多个像素，所以提供了更可信的图元给我们渲染。

最后一个可选阶段是stream output。这个阶段让我们可以使用GPU作为几何引擎。在这个节点我们可以把选择性地把处理后的顶点输出到数组进行更进一步地处理，而不是传到剩下的光线渲染到屏幕上。这些数据可以被CPU使用，也可以被GPU自己使用，在之后的pass中。这个阶段典型地被用于粒子模拟中，比如我们的烟火例子。

这三个阶段按照下面顺序被执行--tessellation、geometry shading、stream output--每个都是可选的。不管它们中哪个被用到，如果我们继续执行管线我们会有一组共坐标系的顶点会被检查是否可见。

#### 2.3.3 剪切

只有当图元整个或者部分在可见体积重才会被传到光栅化阶段。完全在view volume的图元会被保留，完全不在的不会被保留，只有部分在的会被clip。比如一条线一个点在内部一个点在外部，外部的点会被交线点点替代。使用投影矩阵意味着转变后的图元会被单位立方体剪切。在剪切前做view转换以及投影点好处是可以让剪切问题变得一致性。图元总是被单位立方体剪切。

### 2.3.4 屏幕映射

只有被剪切的图元会被传到屏幕映射阶段，坐标系依然是三维的

(略)

### 2.5 像素处理

在这个时刻所有被认为在图元里面的像素点经过之前的几个阶段都得出来了。像素处理pixel processing阶段可以被分成pixel shading和merging。像素着色在图元中对pixel或sample进行per-pixel或per-sample计算和操作的阶段。

#### 2.5.1 像素着色

所有per-pixel着色计算都是在这里进行，使用插值着色数据作为输入。得到的结果是一个或者更多被传递到下一个阶段的颜色数据。不同于三角形构建或遍历阶段，它们通常使用精心设计的硬件来实现，像素着色阶段使用可编程GPU核心进行的。为此，程序员提供程序给pixel shader（或者fragment shader，在OpenGL中的说法），像素着色器可以包含任何希望的计算。一系列的技术可以在这里被应用，其中最重要的一个是texturing。

## 20.1 延迟渲染

我们描述了前向渲染，每个三角形被送到渲染管线，最后屏幕上被绘制上它被着色后的颜色。延迟渲染的观点是在执行任何材质光照计算前执行所有visibility testing和surface property evaluation。

在前向渲染中我们只用一个pass使用一个着色器和一个mesh来计算最终的图像。这个pass获取了材质属性--常量、插值参数或者纹理的值--然后将光线作用于这些数值上。前向渲染中z-prepass方法可以被视作一种几何渲染和着色的轻微解耦，在里面第一个geometry pass只在决定可见性，然后所有的着色工作，包括材质参数获取，被延迟到第二个geometry pass，用于对所有可见像素着色。对于交互式渲染，延迟渲染具体指通过一个初始的geometry pass，所有和可见性有关的材质参数都被生成并保存，然后在post-process中光线被作用于这些被存储的表面数值。在第一个pass中被保存的数值包括了位置(存储为z-depth)、法线、纹理坐标和许多材质参数。这个pass构建了像素点所有几何和材质信息，所以不再需要object了，也就是说，模型几何的贡献可以完全和光照计算解耦。注意overdraw在初始pass中可能发生，

用于存放表面属性的buffers被称作G-buffers，是geometry buffers的缩写，有时也被称作deep buffers，但这种说法也指一个对每个像素存储多个surfaces（fragments）的buffer，所以我们不这样说。图20.2展示了G-buffers包含的典型内容。一个G-buffer可以保存任何程序员想让它储存的内容，也就是任何后续光照计算需要的内容。每个G-buffer是一个分离的render target。一般3到5个render targets被用作G-buffers，但是系统可以使用高达8个。有更多的targets需要更多的带宽，增加了这个buffer是瓶颈的风险。

在pass创建G-buffers后，一个分离的处理被用于计算光照效果。一个方法是一个一个选取光源，使用G-buffers来计算它的效果。对于每个光源我们绘制一个screen-filling quadrilateral并将G-buffers作为纹理来获取。对于每个像素我们可以决定最近表面的位置以及它是否在光源的范围中。如果它是，我们计算光源效果并输出到输出buffer中。我们对每个光源都轮流做此处理，通过blending来添加光源贡献。最后，我们获得所有光源的贡献。

这种处理大概是最不高效的使用G-buffers的方式了，因为每个存储的像素会被每个光源访问，这与前向渲染中用每个光源作用于每个fragment相似。这种方法可能最后比前向渲染还慢，因为有额外的读取写入G-buffers的花费。一种优化是我们可以检测光源体积的屏幕边界（一个球），并用他们来绘制屏幕空间的quadrilateral。通过这种方法像素处理得到了减少，通常效果明显。绘制椭圆排除圆外像素点能取得更好的效果。我们也可以使用第三个屏幕维度，z-depth。
